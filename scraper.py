import feedparser
import json
from datetime import datetime, timedelta
import time

# åŠ æ‹¿å¤§åª’é«”æ¸…å–®ï¼ˆå¯æ¯åˆ†é˜è¼ªæµè™•ç†ä¸€å€‹ï¼‰
canadian_sources = [
    "CBC", "Global News", "CTV News", "National Post", "Ottawa Citizen",
    "Ottawa Sun", "CityNews", "Hill Times", "BNN Bloomberg",
    "Canadaland", "iPolitics", "The Globe and Mail"
]

# Google News RSS å»ºæ§‹ URL
def build_rss_url(source):
    return f"https://news.google.com/rss/search?q=Taiwan+source:{source.replace(' ', '+')}&hl=en-CA&gl=CA&ceid=CA:en"

# è§£æ RSS ä¸¦æ“·å–æ–°èï¼ˆåƒ…é™è¿‘ 24 å°æ™‚ï¼‰
def fetch_articles(source):
    feed = feedparser.parse(build_rss_url(source))
    now = datetime.utcnow()
    cutoff = now - timedelta(days=1)
    articles = []

    if not feed.entries:
        print(f"âš ï¸ {source}: ç„¡è³‡æ–™")
        return []

    for entry in feed.entries:
        try:
            pub = datetime(*entry.published_parsed[:6])
            if pub >= cutoff:
                articles.append({
                    "source": source,
                    "title": entry.title,
                    "url": entry.link,
                    "published": pub.isoformat(),
                    "date": pub.strftime("%Y-%m-%d")
                })
        except Exception as e:
            continue
    return articles

# å»é™¤é‡è¤‡ï¼ˆä¾ title + urlï¼‰
def deduplicate(articles):
    seen = set()
    unique = []
    for a in articles:
        key = (a["title"], a["url"])
        if key not in seen:
            seen.add(key)
            unique.append(a)
    return unique

# ä¸»åŸ·è¡Œé‚è¼¯ï¼ˆæ¨¡æ“¬ä¸€è¼ªæ‰€æœ‰ä¾†æºï¼Œéƒ¨ç½²æ™‚å¯æ”¹ç‚ºæ¯åˆ†é˜è·‘ä¸€å€‹ï¼‰
all_articles = []
for source in canadian_sources:
    print(f"ğŸ” æŠ“å–ä¸­ï¼š{source}")
    all_articles.extend(fetch_articles(source))
    time.sleep(1)  # æ¨¡æ“¬ã€Œæ¯åˆ†é˜è¼ªæµè™•ç†ä¸€å€‹åª’é«”ã€

# æ•´ç†çµæœ
final_articles = deduplicate(all_articles)
final_articles.sort(key=lambda x: x["published"], reverse=True)

news_data = {
    "source": "Google News RSS + Filtered Sources",
    "query": "Taiwan",
    "updated_at": datetime.utcnow().isoformat() + "Z",
    "article_count": len(final_articles),
    "articles": final_articles
}

# å„²å­˜åˆ° data/news.json
with open("data/news.json", "w", encoding="utf-8") as f:
    json.dump(news_data, f, ensure_ascii=False, indent=2)

print(f"âœ… å·²æŠ“å–ä¸¦å„²å­˜ {len(final_articles)} å‰‡æ–°èåˆ° data/news.json")
